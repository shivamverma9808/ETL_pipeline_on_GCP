# ETL Data Pipeline on Google Cloud Platform 
Data Engineering | Cloud Automation 🚀

## 🌟 Overview
An end-to-end **ETL (Extract, Transform, Load) pipeline** built on **Google Cloud Platform (GCP)** for processing and managing large datasets efficiently. Ensures **data quality, scalability, and automated workflow management** for analytics.



## 🛠 Features
- 🔹 **Data Extraction & Transformation:** Cleans and prepares data from multiple sources using Python.  
- 🔹 **Data Masking & Encoding:** Applies masking to sensitive information before loading to BigQuery.  
- 🔹 **Data Loading:** Loads transformed data into **BigQuery** for scalable querying and reporting.  
- 🔹 **Workflow Automation:** Orchestrates ETL workflows using **Cloud Composer (Airflow)** for scheduled execution.  
- 🔹 **Monitoring & Logging:** Implements error-handling and logging to ensure pipeline reliability.  
- 🔹 **Cloud Optimization:** Optimized for storage efficiency and cost-effective data processing.

## 🧰 Tech Stack
![tech](https://github.com/user-attachments/assets/f1753ae8-f8f2-4ac3-bd2d-b7c507a6bd9b)


## 🎯 Use Cases
- Automating ETL workflows for business intelligence and analytics.  
- Scalable cloud-based data engineering solutions for enterprises.  
- Managing large datasets with high performance and reliability.

## 🏗 Architecture
![architetcture](https://github.com/user-attachments/assets/e93f3da3-a23d-4f32-9d98-760258c66a89)

## 📌 How to Run
1. Configure GCP project and authenticate using **Cloud SDK**.  
2. Upload datasets to **Cloud Storage**.  
3. Deploy Airflow DAGs in **Cloud Composer**.  
4. Monitor pipelines through Airflow UI and BigQuery dashboards.  

## 💻 Outcome
- Fully automated ETL pipeline handling large-scale datasets.  
- Optimized storage and query performance in BigQuery.  
- Reliable, maintainable, and scalable data engineering solution.
