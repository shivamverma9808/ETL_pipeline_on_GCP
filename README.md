# ETL Data Pipeline on Google Cloud Platform 
Data Engineering | Cloud Automation ğŸš€

## ğŸŒŸ Overview
An end-to-end **ETL (Extract, Transform, Load) pipeline** built on **Google Cloud Platform (GCP)** for processing and managing large datasets efficiently. Ensures **data quality, scalability, and automated workflow management** for analytics.



## ğŸ›  Features
- ğŸ”¹ **Data Extraction & Transformation:** Cleans and prepares data from multiple sources using Python.  
- ğŸ”¹ **Data Masking & Encoding:** Applies masking to sensitive information before loading to BigQuery.  
- ğŸ”¹ **Data Loading:** Loads transformed data into **BigQuery** for scalable querying and reporting.  
- ğŸ”¹ **Workflow Automation:** Orchestrates ETL workflows using **Cloud Composer (Airflow)** for scheduled execution.  
- ğŸ”¹ **Monitoring & Logging:** Implements error-handling and logging to ensure pipeline reliability.  
- ğŸ”¹ **Cloud Optimization:** Optimized for storage efficiency and cost-effective data processing.

## ğŸ§° Tech Stack
![tech](https://github.com/user-attachments/assets/f1753ae8-f8f2-4ac3-bd2d-b7c507a6bd9b)


## ğŸ¯ Use Cases
- Automating ETL workflows for business intelligence and analytics.  
- Scalable cloud-based data engineering solutions for enterprises.  
- Managing large datasets with high performance and reliability.

## ğŸ— Architecture
![architetcture](https://github.com/user-attachments/assets/e93f3da3-a23d-4f32-9d98-760258c66a89)

## ğŸ“Œ How to Run
1. Configure GCP project and authenticate using **Cloud SDK**.  
2. Upload datasets to **Cloud Storage**.  
3. Deploy Airflow DAGs in **Cloud Composer**.  
4. Monitor pipelines through Airflow UI and BigQuery dashboards.  

## ğŸ’» Outcome
- Fully automated ETL pipeline handling large-scale datasets.  
- Optimized storage and query performance in BigQuery.  
- Reliable, maintainable, and scalable data engineering solution.
